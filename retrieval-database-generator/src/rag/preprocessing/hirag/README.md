# HiRAG: Human-inspired Retrieval-Augmented Generation

<div style="text-align: justify;">
Description will be provided in march 2025.
</div>

![](assets/RAG.png)

---
## Configurable parameters

You can set various parameters in the [config.py](src/rag/config.py) file to customize the behavior of the project.  

| Parameter            | Type        | Default                                           | Description                                                                                                                                                                          |
|----------------------|-------------|---------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| 
| `llm_name`           | `str`       | `"llama3.1-8B"`                                   | Specifies the LLM that will be used for generating the exhaustive list of Question-Answer (QA) pairs.                                                                                |
| `chunking_method`    | `str`       | `"SpaCy"`                                         | Specifies the algorithm used to pre-segment large text into smaller and more manageable context. Available options are listed in [config.py](src/rag/preprocessing/HiRAG/config.py). |
| `chunk_size`         | `int`       | `500`                                             | Defines the length (in characters) of each chunk of context segmented by the `chunking_method`.                                                                                      |
| `chunk_overlap`      | `bool`      | `50`                                              | Defines the overlap (in characters) between consecutive chunk of context.                                                                                                            |
| `max_QA_pair_limit`  | `int`       | `15`                                              | Limit of QA pairs generated by the LLM for each chunk of context. (Must be consistent with the `chunk_size`)                                                                         |
| `prompt`             | `str`       | See [here](src/rag/preprocessing/HiRAG/config.py) | Specifies prompt used by the LLM to generate a QA list that best represent the information contained in the chunk of context.                                                        |
| `parsing_QA_pattern` | `str`       | See [here](src/rag/preprocessing/HiRAG/config.py) | Specifies Regex used to parse the LLM response into a list of QA pairs.                                                                                                              |                                                                                     |


### Run HiRAG system

To test the basic functionality of the HiRAG system for chunking text, you can run:

```bash
python -m hirag.run_example
```

---